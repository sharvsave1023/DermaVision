{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2gvHl-G4McFQ"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Input, Concatenate\n",
        "from tensorflow.keras.applications import EfficientNetB7\n",
        "import tensorflow as tf\n",
        "\n",
        "# Check if GPU is available\n",
        "if tf.test.is_gpu_available():\n",
        "    print(\"GPU is available\")\n",
        "    device_name = tf.test.gpu_device_name()\n",
        "    if device_name != '/device:GPU:0':\n",
        "        raise SystemError('GPU device not found')\n",
        "    print('Found GPU at: {}'.format(device_name))\n",
        "else:\n",
        "    print(\"No GPU found\")\n",
        "\n",
        "train_metadata_path = '/content/drive/MyDrive/derm_data/HAM10000_training_metadata.csv'\n",
        "val_metadata_path = '/content/drive/MyDrive/derm_data/HAM10000_validation_metadata.csv'\n",
        "\n",
        "train_metadata_df = pd.read_csv(train_metadata_path)\n",
        "val_metadata_df = pd.read_csv(val_metadata_path)\n",
        "\n",
        "train_image_dir = '/content/drive/MyDrive/derm_data/HAM10000_training_image_dataset'\n",
        "val_image_dir = '/content/drive/MyDrive/derm_data/HAM10000_validation_image_dataset'\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Add '.jpg' extension to the image_id column in both train and validation dataframes\n",
        "train_metadata_df['image_id'] = train_metadata_df['image_id'] + '.jpg'\n",
        "val_metadata_df['image_id'] = val_metadata_df['image_id'] + '.jpg'\n",
        "\n",
        "# Create the train generator\n",
        "train_generator = train_datagen.flow_from_dataframe(\n",
        "    dataframe=train_metadata_df,\n",
        "    directory=train_image_dir,\n",
        "    x_col='image_id',  # Pass the column name as a string\n",
        "    y_col='dx',  # Pass the column name as a string\n",
        "    target_size=(225, 300),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "# Create the validation generator\n",
        "val_generator = val_datagen.flow_from_dataframe(\n",
        "    dataframe=val_metadata_df,\n",
        "    directory=val_image_dir,\n",
        "    x_col='image_id',  # Pass the column name as a string\n",
        "    y_col='dx',  # Pass the column name as a string\n",
        "    target_size=(225, 300),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "with tf.device('/GPU:0'):\n",
        "    base_model = EfficientNetB7(weights='imagenet', include_top=False, input_shape=(225, 300, 3))\n",
        "\n",
        "    for layer in base_model.layers:\n",
        "        layer.trainable = False\n",
        "\n",
        "    x = base_model.output\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(128, activation='relu')(x)\n",
        "    model_output = Dense(7, activation='softmax')(x)\n",
        "\n",
        "    model = Model(inputs=base_model.input, outputs=model_output)\n",
        "\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    model.fit(\n",
        "        train_generator,\n",
        "        epochs=10,\n",
        "        validation_data=val_generator\n",
        "    )\n",
        "\n",
        "loss, accuracy = model.evaluate(val_generator)\n",
        "print(f'Validation Loss: {loss:.4f}, Validation Accuracy: {accuracy:.4f}')"
      ]
    }
  ]
}